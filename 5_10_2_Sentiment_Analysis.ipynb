{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WaledAmidou/NLP/blob/main/5_10_2_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG4o9qkVprSa",
        "outputId": "0676960a-83ea-4e31-e2c4-09fd142c491a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJvJ2XqZnljv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os , re\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "english_stop_words = stopwords.words('english')\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zto9JJeunlkI"
      },
      "outputs": [],
      "source": [
        "reviews_train = []\n",
        "for line in open(r'/content/full_train.txt', 'r',encoding = 'utf-8'):\n",
        "    \n",
        "    reviews_train.append(line.strip())\n",
        "    \n",
        "reviews_test = []\n",
        "for line in open(r'/content/full_test.txt', 'r',encoding = 'utf-8'):\n",
        "    \n",
        "    reviews_test.append(line.strip())\n",
        "    \n",
        "target = [1 if i < 12500 else 0 for i in range(25000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiQDgFfAnlkM"
      },
      "outputs": [],
      "source": [
        "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "NO_SPACE = \"\"\n",
        "SPACE = \" \"\n",
        "\n",
        "def preprocess_reviews(reviews):\n",
        "    \n",
        "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
        "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
        "    \n",
        "    return reviews\n",
        "\n",
        "reviews_train_clean = preprocess_reviews(reviews_train)\n",
        "reviews_test_clean = preprocess_reviews(reviews_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1txVNvenlkR"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeBPzpR6nlkb",
        "outputId": "577039cb-1f72-4d0e-fc47-1744274caf6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.01: 0.87296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.05: 0.88752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.25: 0.88624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.5: 0.8832\n",
            "Accuracy for C=1: 0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "baseline_vectorizer = CountVectorizer(binary=True)\n",
        "baseline_vectorizer.fit(reviews_train_clean)\n",
        "X_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
        "X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_baseline, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMJxbWkBnlkh",
        "outputId": "dd8130fe-ec23-4484-9988-6386cb028e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 0.88176\n"
          ]
        }
      ],
      "source": [
        "final_model = LogisticRegression(C=0.05)\n",
        "final_model.fit(X_baseline, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_model.predict(X_test_baseline)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZvK51oenlkl"
      },
      "source": [
        "# Remove Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6nmcZ6Dnlko",
        "outputId": "598d8c34-5bf0-4b27-ed93-f9263b73944a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.01: 0.8792\n",
            "Accuracy for C=0.05: 0.88656\n",
            "Accuracy for C=0.25: 0.88304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.5: 0.88288\n",
            "Accuracy for C=1: 0.8824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "def remove_stop_words(corpus):\n",
        "    removed_stop_words = []\n",
        "    for review in corpus:\n",
        "        removed_stop_words.append(\n",
        "            ' '.join([word for word in review.split()  if word not in english_stop_words]))\n",
        "    return removed_stop_words\n",
        "\n",
        "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
        "no_stop_words_test = remove_stop_words(reviews_test_clean)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(no_stop_words_train)\n",
        "X = cv.transform(no_stop_words_train)\n",
        "X_test = cv.transform(no_stop_words_test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split( X, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpI4X34xnlks"
      },
      "source": [
        "# Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr8RzhmCnlkv",
        "outputId": "9ec7a6ad-f429-4d5a-e80c-2ba87a05cb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.01: 0.87008\n",
            "Accuracy for C=0.05: 0.87632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.25: 0.8752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.5: 0.872\n",
            "Accuracy for C=1: 0.86416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "def get_stemmed_text(corpus):\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
        "\n",
        "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
        "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(stemmed_reviews_train)\n",
        "X = cv.transform(stemmed_reviews_train)\n",
        "X_test = cv.transform(stemmed_reviews_test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl6A0j9Dnlk1",
        "outputId": "8f28cd97-79ec-4218-cdcb-a6ad27c3db0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 0.87748\n"
          ]
        }
      ],
      "source": [
        "final_stemmed = LogisticRegression(C=0.05)\n",
        "final_stemmed.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_stemmed.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbvYH-5unlk4"
      },
      "source": [
        "# Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iVNGM1HRZpI",
        "outputId": "6d9a9b3c-f49d-41d8-aede-999843eefcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMwDbp7Wnlk6",
        "outputId": "54157c6b-e7da-4863-ee73-1289c5e6f06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.01: 0.87552\n",
            "Accuracy for C=0.05: 0.88496\n",
            "Accuracy for C=0.25: 0.88304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.5: 0.88064\n",
            "Accuracy for C=1: 0.87632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "def get_lemmatized_text(corpus):\n",
        "    \n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
        "\n",
        "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
        "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(lemmatized_reviews_train)\n",
        "X = cv.transform(lemmatized_reviews_train)\n",
        "X_test = cv.transform(lemmatized_reviews_test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW505hWynlk9",
        "outputId": "b2cd7599-7173-481b-f267-cb93bc0ef5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 0.87436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "final_lemmatized = LogisticRegression(C=0.25)\n",
        "final_lemmatized.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_lemmatized.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buSU6cj1nllA"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSNH4UH1nllC",
        "outputId": "5eb3fbd1-08c9-4831-e605-da4787315447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.01: 0.78416\n",
            "Accuracy for C=0.05: 0.82032\n",
            "Accuracy for C=0.25: 0.8608\n",
            "Accuracy for C=0.5: 0.87168\n",
            "Accuracy for C=1: 0.88192\n"
          ]
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(reviews_train_clean)\n",
        "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
        "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIfA551rnllE",
        "outputId": "c7c90688-6837-4e2b-877d-97fc551c8a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 0.88204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "final_tfidf = LogisticRegression(C=1)\n",
        "final_tfidf.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_tfidf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZyRJOxan3bP",
        "outputId": "6559b0b8-3881-4517-bc71-12c74c7ef84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmWe_fLlnllK"
      },
      "source": [
        "# Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll195yVlnllM",
        "outputId": "74594a07-c835-4776-994b-4dda08a88769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.01: 0.88784\n",
            "Accuracy for C=0.05: 0.88672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.25: 0.88608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.5: 0.88656\n",
            "Accuracy for C=1: 0.88688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(reviews_train_clean)\n",
        "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
        "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split( X, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    svm = LinearSVC(C=c)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ_PWd82nllO",
        "outputId": "172f2918-3978-479b-da96-568ecf2aa5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 0.8974\n"
          ]
        }
      ],
      "source": [
        "final_svm_ngram = LinearSVC(C=0.01)\n",
        "final_svm_ngram.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_svm_ngram.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "apU3_6ozasm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pop4-8kLazLF"
      },
      "source": [
        "# SVM + TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_vectorizer.fit(reviews_train_clean)\n",
        "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
        "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split( X, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    svm = LinearSVC(C=c)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
      ],
      "metadata": {
        "id": "wXzNaBVkbDv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d138d6-a793-4a9b-b93a-ce80614e0b68"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.01: 0.84944\n",
            "Accuracy for C=0.05: 0.88208\n",
            "Accuracy for C=0.25: 0.89744\n",
            "Accuracy for C=0.5: 0.9\n",
            "Accuracy for C=1: 0.89536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v49fpGi7dW9v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpH9E7m6dXpv"
      },
      "source": [
        "# SVM + TF-IDF + no stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(corpus):\n",
        "    removed_stop_words = []\n",
        "    for review in corpus:\n",
        "        removed_stop_words.append(\n",
        "            ' '.join([word for word in review.split()  if word not in english_stop_words]))\n",
        "    return removed_stop_words\n",
        "\n",
        "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
        "no_stop_words_test = remove_stop_words(reviews_test_clean)"
      ],
      "metadata": {
        "id": "5vKJuCDQdwz3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(no_stop_words_train)\n",
        "\n",
        "X = tfidf_vectorizer.transform(no_stop_words_train)\n",
        "X_test = tfidf_vectorizer.transform(no_stop_words_test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split( X, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    svm = LinearSVC(C=c)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uvm2siJdaH-",
        "outputId": "b414e694-ba46-4c2b-831e-d48abfaaa17e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for C=0.01: 0.86112\n",
            "Accuracy for C=0.05: 0.88704\n",
            "Accuracy for C=0.25: 0.89856\n",
            "Accuracy for C=0.5: 0.89648\n",
            "Accuracy for C=1: 0.89024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8jJTjSoKg-7"
      },
      "source": [
        "# SVM + CountVect + no stopwords + lemmatisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(corpus):\n",
        "    removed_stop_words = []\n",
        "    for review in corpus:\n",
        "        removed_stop_words.append(\n",
        "            ' '.join([word for word in review.split()  if word not in english_stop_words]))\n",
        "    return removed_stop_words\n",
        "\n",
        "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
        "no_stop_words_test = remove_stop_words(reviews_test_clean)"
      ],
      "metadata": {
        "id": "o7h0fSQsKy7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemmatized_text(corpus):\n",
        "    \n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
        "\n",
        "lemmatized_reviews_train = get_lemmatized_text(no_stop_words_train)\n",
        "lemmatized_reviews_test = get_lemmatized_text(no_stop_words_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "GEdvosX6Kacc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(lemmatized_reviews_train)\n",
        "X = cv.transform(lemmatized_reviews_train)\n",
        "X_test = cv.transform(lemmatized_reviews_test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split( X, target, train_size = 0.75)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    svm = LinearSVC(C=c)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n"
      ],
      "metadata": {
        "id": "ZDCLINYzK_iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NNAh78FuLSkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvrvhx2yLmzj"
      },
      "source": [
        "# SVM + TF-IDF + no stopwords + lemmatisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yYfND0XPLSSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(lemmatized_reviews_train)\n",
        "\n",
        "X = tfidf_vectorizer.transform(lemmatized_reviews_train)\n",
        "X_test = tfidf_vectorizer.transform(lemmatized_reviews_test)"
      ],
      "metadata": {
        "id": "LcLJClh_LR-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}